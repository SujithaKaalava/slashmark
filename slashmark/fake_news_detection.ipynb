{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f291954-2072-4386-a62f-24135a6e6368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Temp\\ipykernel_13192\\867872218.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "import nltk.corpus \n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05da33b7-d6ba-4f18-88da-281e16569c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news = pd.read_csv(\"C:\\\\Users\\\\sujit\\\\OneDrive\\\\Desktop\\\\train.csv\")\n",
    "test_news=pd.read_csv(\"C:\\\\Users\\\\sujit\\\\OneDrive\\\\Desktop\\\\test.csv\")\n",
    "valid_news=pd.read_csv(\"C:\\\\Users\\\\sujit\\\\OneDrive\\\\Desktop\\\\valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7c8835-a0ee-47e5-ae38-afe9f1cb558b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jim Dunnam has not lived in the district he re...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm the only person on this stage who has work...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>However, it took $19.5 million in Oregon Lotte...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Says GOP primary opponents Glenn Grothman and ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Statement  Label\n",
       "0  Says the Annies List political group supports ...  False\n",
       "1  When did the decline of coal start? It started...   True\n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   True\n",
       "3  Health care reform legislation is likely to ma...  False\n",
       "4  The economic turnaround started at the end of ...   True\n",
       "5  The Chicago Bears have had more starting quart...   True\n",
       "6  Jim Dunnam has not lived in the district he re...  False\n",
       "7  I'm the only person on this stage who has work...   True\n",
       "8  However, it took $19.5 million in Oregon Lotte...   True\n",
       "9  Says GOP primary opponents Glenn Grothman and ...   True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ea30c4-c902-4a98-ac83-916056b327e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset size:\n",
      "(10240, 2)\n",
      "                                           Statement  Label\n",
      "0  Says the Annies List political group supports ...  False\n",
      "1  When did the decline of coal start? It started...   True\n",
      "2  Hillary Clinton agrees with John McCain \"by vo...   True\n",
      "3  Health care reform legislation is likely to ma...  False\n",
      "4  The economic turnaround started at the end of ...   True\n",
      "5  The Chicago Bears have had more starting quart...   True\n",
      "6  Jim Dunnam has not lived in the district he re...  False\n",
      "7  I'm the only person on this stage who has work...   True\n",
      "8  However, it took $19.5 million in Oregon Lotte...   True\n",
      "9  Says GOP primary opponents Glenn Grothman and ...   True\n",
      "(2551, 2)\n",
      "                                           Statement  Label\n",
      "0  Building a wall on the U.S.-Mexico border will...   True\n",
      "1  Wisconsin is on pace to double the number of l...  False\n",
      "2  Says John McCain has done nothing to help the ...  False\n",
      "3  Suzanne Bonamici supports a plan that will cut...   True\n",
      "4  When asked by a reporter whether hes at the ce...  False\n",
      "5  Over the past five years the federal governmen...   True\n",
      "6  Says that Tennessee law requires that schools ...   True\n",
      "7  Says Vice President Joe Biden \"admits that the...  False\n",
      "8  Donald Trump is against marriage equality. He ...   True\n",
      "9  We know that more than half of Hillary Clinton...  False\n",
      "(2571, 2)\n",
      "                                           Statement  Label\n",
      "0  We have less Americans working now than in the...  FALSE\n",
      "1  When Obama was sworn into office, he DID NOT u...  FALSE\n",
      "2  Says Having organizations parading as being so...  FALSE\n",
      "3     Says nearly half of Oregons children are poor.   TRUE\n",
      "4  On attacks by Republicans that various program...   TRUE\n",
      "5  Says when armed civilians stop mass shootings ...  FALSE\n",
      "6  Says Tennessee is providing millions of dollar...   TRUE\n",
      "7  The health care reform plan would set limits s...  FALSE\n",
      "8  Says Donald Trump started his career back in 1...   TRUE\n",
      "9  Bill White has a long history of trying to lim...   TRUE\n"
     ]
    }
   ],
   "source": [
    "#data observaion\n",
    "def data_obs():\n",
    "    print(\"training dataset size:\")\n",
    "    print(train_news.shape)\n",
    "    print(train_news.head(10))\n",
    "\n",
    "    #below dataset were used for testing and validation purposes\n",
    "    print(test_news.shape)\n",
    "    print(test_news.head(10))\n",
    "    \n",
    "    print(valid_news.shape)\n",
    "    print(valid_news.head(10))\n",
    "data_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac62551-dd75-40ca-b342-4999564f5a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Temp\\ipykernel_13192\\2397850315.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  return sns.countplot(x='Label', data=dataFile, palette='hls')\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\sujit\\AppData\\Local\\Temp\\ipykernel_13192\\2397850315.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  return sns.countplot(x='Label', data=dataFile, palette='hls')\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\sujit\\AppData\\Local\\Temp\\ipykernel_13192\\2397850315.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  return sns.countplot(x='Label', data=dataFile, palette='hls')\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Label', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_distribution(dataFile):\n",
    "    \n",
    "    return sns.countplot(x='Label', data=dataFile, palette='hls')\n",
    "    \n",
    "\n",
    "#by calling below we can see that training, test and valid data seems to be failry evenly distributed between the classes\n",
    "create_distribution(train_news)\n",
    "create_distribution(test_news)\n",
    "create_distribution(valid_news)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b755b5-57ad-433d-b8eb-739410c4f8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data qualitites...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10240 entries, 0 to 10239\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Statement  10240 non-null  object\n",
      " 1   Label      10240 non-null  bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 90.1+ KB\n",
      "check finished.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2551 entries, 0 to 2550\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Statement  2551 non-null   object\n",
      " 1   Label      2551 non-null   bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 22.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2571 entries, 0 to 2570\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Statement  2571 non-null   object\n",
      " 1   Label      2569 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 40.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#data integrity check (missing label values)\n",
    "#none of the datasets contains missing values therefore no cleaning required\n",
    "def data_qualityCheck():\n",
    "    \n",
    "    print(\"Checking data qualitites...\")\n",
    "    train_news.isnull().sum()\n",
    "    train_news.info()\n",
    "        \n",
    "    print(\"check finished.\")\n",
    "\n",
    "    #below datasets were used to \n",
    "    test_news.isnull().sum()\n",
    "    test_news.info()\n",
    "\n",
    "    valid_news.isnull().sum()\n",
    "    valid_news.info()\n",
    "data_qualityCheck()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533ce0e2-dcb4-476b-830c-b46cf2df0a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Statement    0\n",
       "Label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc365db-b51d-4035-9ac2-1e7b7525c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "eng_stemmer=SnowballStemmer('english')\n",
    "stopwords=set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2881730-a470-4978-b341-7c89650cc7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac29b70-19cc-454b-be3a-df091e46b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens,stemmer):\n",
    "    stemmed=[]\n",
    "    for token in tokens:\n",
    "        stemmed.append(stemmer.stem(token))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f05fdcf-d38f-4988-aa78-6346c061f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the data\n",
    "def process_data(data,exclude_stopwords=True,stem=True):\n",
    "    tokens = [w.lower() for w in data]\n",
    "    tokens_stemmed=tokens\n",
    "    tokens_stemmed=stem_token(tokens,eng_stemmer)\n",
    "    tokens_stemmed=[w for w in tokens_stemmed if w not in stopwords]\n",
    "    return tokens_stemmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8dee9f-1987-4fcc-8a5c-78b6c7e80604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating n grams \n",
    "#unigram\n",
    "def create_unigram(words):\n",
    "    assert type(words)==list\n",
    "    return words\n",
    "#bigram\n",
    "def create_bigram(words):\n",
    "    skip=0\n",
    "    assert type(words)==list\n",
    "    join_str=\" \"\n",
    "    Len=len(words)\n",
    "    if Len>1:\n",
    "        lst=[]\n",
    "        for i in range(Len-1):\n",
    "            for k in range(1,skip+2):\n",
    "                if i+k<Len:\n",
    "                    lst.append(join_str.join([words[i],words[i+k]]))\n",
    "    else:\n",
    "        lst=create_unigram(words)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25695fea-912b-411b-940b-92dd01f8be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trigram\n",
    "def create_trigram(words):\n",
    "    assert type(words)==list\n",
    "    skip=1\n",
    "    join_str=\" \"\n",
    "    Len=len(words)\n",
    "    if Len>2:\n",
    "        lst=[]\n",
    "        for i in range(Len-1):\n",
    "            for k1 in range(1,skip+2):\n",
    "                for k2 in range(1,skip+2):\n",
    "                    if i+k1<Len and i+k2<Len:\n",
    "                        lst.append(join_str.join([words[i],words[i+k1],words[i+k2]]))\n",
    "    else:\n",
    "        lst=create_bigram(words)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6a8f6c5-174b-4660-91e9-36849485bed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Statement  Label\n",
       "0  Says the Annies List political group supports ...  False\n",
       "1  When did the decline of coal start? It started...   True\n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   True\n",
       "3  Health care reform legislation is likely to ma...  False\n",
       "4  The economic turnaround started at the end of ...   True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ac43b-df3d-46c9-b49a-cacdba882c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d71310-1264-4093-8d76-8e844735ae25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Statement  Label\n",
       "0  Says the Annies List political group supports ...  False\n",
       "1  When did the decline of coal start? It started...   True\n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   True\n",
       "3  Health care reform legislation is likely to ma...  False\n",
       "4  The economic turnaround started at the end of ...   True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f3af6-0aae-4a0b-b94d-92646b29675e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b942b1-b50d-4c96-9f5c-16cbdc3fb4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer()\n",
      "  (0, 9676)\t1\n",
      "  (0, 10988)\t1\n",
      "  (0, 1044)\t1\n",
      "  (0, 6639)\t1\n",
      "  (0, 8376)\t1\n",
      "  (0, 5115)\t1\n",
      "  (0, 10709)\t1\n",
      "  (0, 11036)\t1\n",
      "  (0, 11296)\t1\n",
      "  (0, 615)\t1\n",
      "  (0, 7728)\t1\n",
      "  (0, 3278)\t1\n",
      "  (1, 10988)\t1\n",
      "  (1, 11934)\t2\n",
      "  (1, 3434)\t1\n",
      "  (1, 3185)\t1\n",
      "  (1, 7672)\t1\n",
      "  (1, 2475)\t1\n",
      "  (1, 10425)\t1\n",
      "  (1, 6052)\t1\n",
      "  (1, 10426)\t2\n",
      "  (1, 7418)\t1\n",
      "  (1, 4860)\t1\n",
      "  (1, 11138)\t1\n",
      "  (1, 7674)\t1\n",
      "  :\t:\n",
      "  (10239, 10988)\t1\n",
      "  (10239, 7672)\t2\n",
      "  (10239, 11110)\t2\n",
      "  (10239, 5267)\t1\n",
      "  (10239, 7828)\t1\n",
      "  (10239, 7824)\t1\n",
      "  (10239, 1159)\t1\n",
      "  (10239, 12151)\t2\n",
      "  (10239, 6327)\t1\n",
      "  (10239, 6603)\t1\n",
      "  (10239, 11013)\t1\n",
      "  (10239, 11004)\t1\n",
      "  (10239, 3309)\t1\n",
      "  (10239, 12158)\t1\n",
      "  (10239, 11660)\t2\n",
      "  (10239, 799)\t1\n",
      "  (10239, 2568)\t1\n",
      "  (10239, 11622)\t1\n",
      "  (10239, 2549)\t1\n",
      "  (10239, 10660)\t1\n",
      "  (10239, 8996)\t1\n",
      "  (10239, 10918)\t1\n",
      "  (10239, 3989)\t1\n",
      "  (10239, 10594)\t1\n",
      "  (10239, 6853)\t1\n"
     ]
    }
   ],
   "source": [
    "countV = CountVectorizer()\n",
    "train_count = countV.fit_transform(train_news['Statement'].values)\n",
    "\n",
    "print(countV)\n",
    "print(train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8075879b-32a1-4fce-bddd-0359e081c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print training doc term matrix\n",
    "#we have matrix of size of (10240, 12196) by calling below\n",
    "def get_countVectorizer_stats():\n",
    "    \n",
    "    #vocab size\n",
    "    train_count.shape\n",
    "\n",
    "    #check vocabulary using below command\n",
    "    print(countV.vocabulary_)\n",
    "\n",
    "    #get feature names\n",
    "    print(countV.get_feature_names()[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44166151-ec89-4c28-94a9-d56a16c4b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tf-df frequency features\n",
    "#tf-idf \n",
    "tfidfV = TfidfTransformer()\n",
    "train_tfidf = tfidfV.fit_transform(train_count)\n",
    "\n",
    "def get_tfidf_stats():\n",
    "    train_tfidf.shape\n",
    "    #get train data feature names \n",
    "    print(train_tfidf.A[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e57a051e-bfe6-4dd0-b7cb-47df3e3a670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words - with n-grams\n",
    "#countV_ngram = CountVectorizer(ngram_range=(1,3),stop_words='english')\n",
    "#tfidf_ngram  = TfidfTransformer(use_idf=True,smooth_idf=True)\n",
    "\n",
    "tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13f7df5d-ce6b-4047-b5cd-ec73b9f6e15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Says the Annies List political group supports ...\n",
      "1        When did the decline of coal start? It started...\n",
      "2        Hillary Clinton agrees with John McCain \"by vo...\n",
      "3        Health care reform legislation is likely to ma...\n",
      "4        The economic turnaround started at the end of ...\n",
      "                               ...                        \n",
      "10235    There are a larger number of shark attacks in ...\n",
      "10236    Democrats have now become the party of the [At...\n",
      "10237    Says an alternative to Social Security that op...\n",
      "10238    On lifting the U.S. Cuban embargo and allowing...\n",
      "10239    The Department of Veterans Affairs has a manua...\n",
      "Name: Statement, Length: 10240, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#POS Tagging\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "\n",
    "cutoff = int(.75 * len(tagged_sentences))\n",
    "training_sentences =train_news['Statement']\n",
    " \n",
    "print(training_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54a745ef-0243-4699-b2ff-3e4e3f8dbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training POS tagger based on words\n",
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2f4c608-9f4f-4a44-9485-80d0e5b4cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to strip tags from tagged corpus\t\n",
    "def untag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence]\n",
    "#Using Word2Vec \n",
    "with open(\"C:\\\\Users\\\\sujit\\\\OneDrive\\\\Desktop\\\\glove.6B.50d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "           for line in lines}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f014537-2ad6-4829-9b5e-d0799ed75b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = gensim.models.Word2Vec(X, size=100) # x be tokenized text\n",
    "#w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc65395a-c7a9-4c82-ac02-cfbc3d7ad913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2062a6c4-6bb7-4425-b00d-eabda4b6c475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8dab698-466f-40ae-befa-e124754d3b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6072128577028616"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#string to test\n",
    "doc_new = ['obama is running for president in 2016']\n",
    "\n",
    "#the feature selection has been done in FeatureSelection.py module. here we will create models using those features for prediction\n",
    "\n",
    "#first we will use bag of words techniques\n",
    "\n",
    "#building classifier using naive bayes \n",
    "nb_pipeline = Pipeline([\n",
    "        ('NBCV',countV),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "nb_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_nb = nb_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_nb == test_news['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffca1367-7ff9-46d8-8cd1-9e149172702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building classifier using logistic regression\n",
    "logR_pipeline = Pipeline([\n",
    "        ('LogRCV',countV),\n",
    "        ('LogR_clf',LogisticRegression())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea5cf62e-e624-4d49-937d-02e2961ebb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6013328106624853"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logR_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_LogR = logR_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_LogR == test_news['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d9e6eba-ea92-4206-91a1-bfdb681852bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5723245785966288"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building Linear SVM classfier\n",
    "svm_pipeline = Pipeline([\n",
    "        ('svmCV',countV),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_svm = svm_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_svm == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bfeae8f-7278-44cd-ad69-ac04f4343748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6107408859270874"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using SVM Stochastic Gradient Descent on hinge loss\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_pipeline = Pipeline([\n",
    "        ('svm2CV',countV),\n",
    "        ('svm2_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=5))\n",
    "        ])\n",
    "\n",
    "sgd_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_sgd = sgd_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_sgd == test_news['Label'])\n",
    "\n",
    "sgd_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_sgd = sgd_pipeline.predict(test_news['Statement'])\n",
    "np.mean(predicted_sgd == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bdd4ad9-f9b0-48b4-8dc0-6f5a2f34855b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6260290082320659"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest\n",
    "random_forest = Pipeline([\n",
    "        ('rfCV',countV),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=200,n_jobs=3))\n",
    "        ])\n",
    "    \n",
    "random_forest.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_rf = random_forest.predict(test_news['Statement'])\n",
    "np.mean(predicted_rf == test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cb092c-26b8-4318-bee3-6a29652a051d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "358372d3-7c97-4f25-8770-b658b7cf347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.66961153965076\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2118 2370]\n",
      " [1664 4088]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.6467896359367876\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2252 2236]\n",
      " [1934 3818]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6104687487924284\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2260 2228]\n",
      " [2246 3506]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6472232052380189\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2210 2278]\n",
      " [1879 3873]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.7046152940033436\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1802 2686]\n",
      " [1162 4590]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#User defined functon for K-Fold cross validatoin\n",
    "def build_confusion_matrix(classifier):\n",
    "    \n",
    "    k_fold = KFold(n_splits=5)\n",
    "    scores = []\n",
    "    confusion = np.array([[0,0],[0,0]])\n",
    "\n",
    "    for train_ind, test_ind in k_fold.split(train_news):\n",
    "        train_text = train_news.iloc[train_ind]['Statement'] \n",
    "        train_y = train_news.iloc[train_ind]['Label']\n",
    "    \n",
    "        test_text = train_news.iloc[test_ind]['Statement']\n",
    "        test_y = train_news.iloc[test_ind]['Label']\n",
    "        \n",
    "        classifier.fit(train_text,train_y)\n",
    "        predictions = classifier.predict(test_text)\n",
    "        \n",
    "        confusion += confusion_matrix(test_y,predictions)\n",
    "        score = f1_score(test_y,predictions)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return (print('Total statements classified:', len(train_news)),\n",
    "    print('Score:', sum(scores)/len(scores)),\n",
    "    print('score length', len(scores)),\n",
    "    print('Confusion matrix:'),\n",
    "    print(confusion))\n",
    "    \n",
    "#K-fold cross validation for all classifiers\n",
    "build_confusion_matrix(nb_pipeline)\n",
    "build_confusion_matrix(logR_pipeline)\n",
    "build_confusion_matrix(svm_pipeline)\n",
    "build_confusion_matrix(sgd_pipeline)\n",
    "build_confusion_matrix(random_forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50d23be7-c01c-47e5-915c-55a79138e990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5938847510780086"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enhancing  the features using term frequency weights with various n-grams\n",
    "##Now using n-grams\n",
    "#naive-bayes classifier\n",
    "nb_pipeline_ngram = Pipeline([\n",
    "        ('nb_tfidf',tfidf_ngram),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "nb_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_nb_ngram = nb_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_nb_ngram == test_news['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e60a618-4787-4ae5-99c4-2c8539d67482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6185809486475892"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression classifier\n",
    "logR_pipeline_ngram = Pipeline([\n",
    "        ('LogR_tfidf',tfidf_ngram),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_LogR_ngram = logR_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_LogR_ngram == test_news['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d238101-20c6-433c-a20b-782338a7be85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6170129361034888"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear SVM classifier\n",
    "svm_pipeline_ngram = Pipeline([\n",
    "        ('svm_tfidf',tfidf_ngram),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_svm_ngram = svm_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_svm_ngram == test_news['Label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d91ce70d-9455-4b51-b0c6-6221dcb83b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5417483339866719"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sgd classifier\n",
    "sgd_pipeline_ngram = Pipeline([\n",
    "         ('sgd_tfidf',tfidf_ngram),\n",
    "         ('sgd_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=5))\n",
    "         ])\n",
    "\n",
    "sgd_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_sgd_ngram = sgd_pipeline_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_sgd_ngram == test_news['Label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61938247-3934-4e17-9f5b-ffab28976844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5993727949823598"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest classifier\n",
    "random_forest_ngram = Pipeline([\n",
    "        ('rf_tfidf',tfidf_ngram),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3))\n",
    "        ])\n",
    "    \n",
    "random_forest_ngram.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_rf_ngram = random_forest_ngram.predict(test_news['Statement'])\n",
    "np.mean(predicted_rf_ngram == test_news['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6b90a93-37b5-4b2a-93d9-6d45619c1664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.7224053159841455\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[ 758 3730]\n",
      " [ 390 5362]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.7042876638233403\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1581 2907]\n",
      " [1045 4707]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6790920142902143\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2016 2472]\n",
      " [1524 4228]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.7190643331130575\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[   5 4483]\n",
      " [   6 5746]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.6605745061646336\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1996 2492]\n",
      " [1686 4066]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-fold cross validation for all classifiers\n",
    "build_confusion_matrix(nb_pipeline_ngram)\n",
    "build_confusion_matrix(logR_pipeline_ngram)\n",
    "build_confusion_matrix(svm_pipeline_ngram)\n",
    "build_confusion_matrix(sgd_pipeline_ngram)\n",
    "build_confusion_matrix(random_forest_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923bf7f-99a4-4cdb-889f-716da885b69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69e39e0d-8bf4-41c6-af5a-1f9455b3a1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.19      0.30      1169\n",
      "        True       0.58      0.94      0.71      1382\n",
      "\n",
      "    accuracy                           0.59      2551\n",
      "   macro avg       0.65      0.56      0.51      2551\n",
      "weighted avg       0.64      0.59      0.52      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.39      0.48      1169\n",
      "        True       0.61      0.81      0.70      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.62      0.60      0.59      2551\n",
      "weighted avg       0.62      0.62      0.60      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.47      0.53      1169\n",
      "        True       0.62      0.74      0.68      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.61      0.61      0.60      2551\n",
      "weighted avg       0.62      0.62      0.61      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00      1169\n",
      "        True       0.54      1.00      0.70      1382\n",
      "\n",
      "    accuracy                           0.54      2551\n",
      "   macro avg       0.27      0.50      0.35      2551\n",
      "weighted avg       0.29      0.54      0.38      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.48      0.52      1169\n",
      "        True       0.61      0.70      0.65      1382\n",
      "\n",
      "    accuracy                           0.60      2551\n",
      "   macro avg       0.59      0.59      0.59      2551\n",
      "weighted avg       0.60      0.60      0.59      2551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2551,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(test_news['Label'], predicted_nb_ngram))\n",
    "print(classification_report(test_news['Label'], predicted_LogR_ngram))\n",
    "print(classification_report(test_news['Label'], predicted_svm_ngram))\n",
    "print(classification_report(test_news['Label'], predicted_sgd_ngram))\n",
    "print(classification_report(test_news['Label'], predicted_rf_ngram))\n",
    "\n",
    "test_news['Label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb74be-1fde-47e0-a4b2-0aee2d699345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6367fd-2d74-44a0-af13-8ee458dbd072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6529b5fb-9216-4654-bdae-9525f449e3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc02c24-a9e2-4739-b8c0-a7e40a803c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842b5f8-a6dd-4696-9f6f-cbd558c1d7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9053871-13bc-4a78-8a4b-6fc776696a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e6ab2-963c-4087-9092-8e44608e0465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a60cb-362b-4bf8-bcce-b29b8ac44d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_news['Label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f2fca-8bb8-4ad9-9670-775049eb6e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Out of all the models fitted, we would take 2 best performing model. we would call them candidate models\n",
    "from the confusion matrix, we can see that random forest and logistic regression are best performing \n",
    "in terms of precision and recall (take a look into false positive and true negative counts which appeares\n",
    "to be low compared to rest of the models)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05ae8f62-0f13-4a8e-9b8e-37d1c5347a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  1.35516825,   2.18890266,   2.66903863,   2.6568831 ,\n",
       "          3.50592947,   3.50051637,   4.29384422,   4.51862507,\n",
       "          5.30084324,   4.99881687,   2.0587429 ,   2.00322556,\n",
       "          2.66911397,   2.64000144,   3.50833879,   3.42910318,\n",
       "          4.27120347,   4.29970508,   5.0109684 ,   5.09818287,\n",
       "          2.04751005,   1.99664087,   2.66656342,   2.65212808,\n",
       "          3.59457164,   3.50301332,   4.42654409,   4.51018624,\n",
       "          5.33040061,   5.21014552,   2.08566389,   1.94912949,\n",
       "          2.71004839,   2.67715216,   3.6015563 ,   3.73028049,\n",
       "          4.91737738,   4.62947974,   5.36612597,   5.37673998,\n",
       "          2.15815644,   2.0322618 ,   2.84341497,   2.83086476,\n",
       "          3.80058889,   3.83376212,   4.76895208,   4.68434896,\n",
       "          5.75854092,   5.66138206,   2.24452662,   2.03075919,\n",
       "          3.12066364,   2.98355775,   3.98719664,   3.91121058,\n",
       "          5.00277896,   5.0120985 ,   5.88476043,   6.30255117,\n",
       "          2.37210455,   2.17348862,   3.08491917,   3.11340194,\n",
       "          4.14782467,   4.14333482,   5.38357325,   5.30323954,\n",
       "          6.2864666 ,   6.41822286,   2.39152436,   2.20445919,\n",
       "          3.26946797,   3.17162261,   4.50013413,   4.50990109,\n",
       "          5.76916947,   5.95478868,   6.92403774,   6.93385925,\n",
       "          2.56215739,   2.22491403,   3.51257019,   3.47128954,\n",
       "          4.76855998,   4.84488544,   6.30900903,   6.17445326,\n",
       "          7.20788283,   7.64429822,   2.70618258,   2.37476091,\n",
       "          3.87069912, 138.97003365,   5.56108956,   6.07918739,\n",
       "          7.12906942,   6.96483955,   8.29014931,   8.46479869,\n",
       "          2.7899941 ,   2.54729848,   4.05005884,   3.95401387,\n",
       "          5.61928906,   5.74220858,   7.53811464,   7.45598564,\n",
       "          8.93979278,   8.75472569,   2.80382099,   2.53969898,\n",
       "          4.19699254,   4.28193994,   6.21124582,   6.23167677,\n",
       "          8.20867343,   8.04127183,   9.50709257,   9.69146743,\n",
       "          3.23036265,   2.67392321,   4.635495  ,   4.54631557,\n",
       "          6.97420406,   7.24902534,  10.09266438,  10.45091839,\n",
       "         13.10134263,  13.14848394,   3.87752352,   2.66128879,\n",
       "          4.95879951,   5.20816226,   8.29541941,   8.54434624,\n",
       "         10.52506962,  11.49873581,  12.90388651,  14.89569883,\n",
       "          4.84033146,   2.9735961 ,   5.55238895,   5.65206351,\n",
       "          8.63411117,   8.33167   ,  13.07784824,  13.46714711,\n",
       "         15.79978666,  15.63610301]),\n",
       " 'std_fit_time': array([5.46836695e-01, 7.12427337e-02, 3.69551703e-02, 3.30551694e-02,\n",
       "        4.72019455e-02, 1.00933178e-01, 1.45464277e-01, 1.13793077e-01,\n",
       "        1.34281226e-01, 8.79263487e-02, 1.01234348e-01, 1.60676468e-02,\n",
       "        7.34323642e-02, 1.00797321e-01, 4.36127322e-02, 8.39780401e-02,\n",
       "        5.77262867e-02, 6.91273381e-02, 2.09226027e-01, 2.24294432e-01,\n",
       "        4.44229151e-02, 3.43591171e-02, 6.41068717e-02, 2.07715442e-02,\n",
       "        1.06392475e-01, 7.66195812e-02, 1.51139393e-01, 9.88904707e-02,\n",
       "        1.16440820e-01, 9.34501235e-02, 1.16126399e-01, 1.24319218e-02,\n",
       "        4.79914134e-02, 1.99149571e-02, 1.47567494e-01, 1.18378008e-01,\n",
       "        3.19088264e-01, 1.28086230e-01, 1.61234066e-01, 2.13916168e-01,\n",
       "        7.85216018e-02, 4.17263828e-02, 6.19141234e-02, 6.83108181e-02,\n",
       "        1.22291332e-01, 8.30154609e-02, 9.44623780e-02, 8.77940592e-02,\n",
       "        1.20879429e-01, 6.52574484e-02, 9.50573142e-02, 4.75930712e-02,\n",
       "        1.33033217e-01, 6.65347578e-02, 1.44512962e-01, 4.57148920e-02,\n",
       "        1.35919467e-01, 9.88154999e-02, 2.18927451e-01, 4.98499433e-02,\n",
       "        1.52236075e-01, 4.32934277e-02, 5.56545703e-02, 7.47512898e-02,\n",
       "        5.10104999e-02, 5.17537625e-02, 1.86275434e-01, 6.24816142e-02,\n",
       "        1.71211118e-01, 1.25897488e-01, 1.29078635e-01, 4.82724576e-02,\n",
       "        4.44495551e-02, 5.60346991e-02, 7.57488027e-02, 6.05140107e-02,\n",
       "        3.12949520e-01, 2.64689917e-01, 2.77907466e-01, 3.42946638e-01,\n",
       "        3.96003095e-01, 2.91868126e-01, 4.67653289e-02, 7.93830071e-02,\n",
       "        2.93094782e-01, 8.32766341e-02, 3.21717797e-01, 1.46689108e-01,\n",
       "        2.91039513e-01, 2.62687894e-01, 1.94221380e-01, 6.38098631e-02,\n",
       "        1.75284682e-01, 2.70396891e+02, 2.68059534e-01, 1.89467532e-01,\n",
       "        5.18809757e-01, 8.29999134e-02, 7.65620962e-02, 2.46731507e-01,\n",
       "        2.21990986e-01, 3.58590655e-02, 1.50437820e-01, 7.33269257e-02,\n",
       "        2.60512394e-01, 8.16234408e-02, 1.77237746e-01, 8.29880227e-02,\n",
       "        3.16141099e-01, 1.54756200e-01, 2.89769054e-01, 4.78522781e-02,\n",
       "        1.02700194e-01, 6.01852504e-02, 2.03870892e-01, 1.17463149e-01,\n",
       "        3.18075904e-01, 1.39706857e-01, 2.77442222e-01, 2.57037844e-01,\n",
       "        3.69190065e-01, 9.39349377e-02, 2.37225736e-01, 7.77277583e-02,\n",
       "        4.64723085e-01, 5.16513887e-01, 2.63696851e-01, 5.63135311e-01,\n",
       "        9.49397536e-01, 2.93745621e-01, 8.39247650e-01, 3.46493743e-02,\n",
       "        2.33962384e-01, 1.77384539e-01, 4.82892237e-01, 3.06421610e-01,\n",
       "        5.27091683e-01, 7.56781308e-01, 7.77090577e-01, 1.24795423e+00,\n",
       "        7.86835133e-01, 1.20003843e-01, 3.04450374e-01, 1.19558967e-01,\n",
       "        8.16364537e-01, 1.93792693e-01, 1.05876369e+00, 1.01729111e+00,\n",
       "        1.54046774e+00, 1.83202121e+00]),\n",
       " 'mean_score_time': array([  0.20940027,   0.2601141 ,   0.34940844,   0.355618  ,\n",
       "          0.43449159,   0.38896956,   0.54454937,   0.52274251,\n",
       "          0.68098941,   0.65252848,   0.25104799,   0.23948073,\n",
       "          0.34714885,   0.33934383,   0.39346867,   0.39978175,\n",
       "          0.51278377,   0.49269428,   0.65101757,   0.63458724,\n",
       "          0.26054335,   0.24666529,   0.35078635,   0.33351712,\n",
       "          0.42474618,   0.40147233,   0.53107715,   0.53614788,\n",
       "          0.70448089,   0.66405945,   0.24847765,   0.2440062 ,\n",
       "          0.32512021,   0.34038153,   0.41098595,   0.40008602,\n",
       "          0.58300533,   0.50007029,   0.70499606,   0.66813149,\n",
       "          0.24586215,   0.24583917,   0.33226552,   0.33766656,\n",
       "          0.45558462,   0.41407967,   0.56446543,   0.5619854 ,\n",
       "          0.71985769,   0.70184913,   0.2581439 ,   0.25737114,\n",
       "          0.36545377,   0.3363451 ,   0.38300319,   0.41572514,\n",
       "          0.60456662,   0.5557404 ,   0.69577003,   0.70552578,\n",
       "          0.26029081,   0.24697704,   0.36038542,   0.33464804,\n",
       "          0.40726061,   0.41098485,   0.58109465,   0.5746593 ,\n",
       "          0.69884377,   0.66910996,   0.25191388,   0.24390597,\n",
       "          0.34455462,   0.33599725,   0.43810763,   0.42787786,\n",
       "          0.60235839,   0.54240332,   0.70294137,   0.71620231,\n",
       "          0.2388299 ,   0.26426873,   0.34839201,   0.32945518,\n",
       "          0.43939066,   0.45635676,   0.60123458,   0.58873572,\n",
       "          0.70819392,   0.67803168,   0.29584169,   0.24445391,\n",
       "        135.55681844,   0.33640871,   0.4428215 ,   0.4634757 ,\n",
       "          0.64287562,   0.61996522,   0.72671838,   0.74574618,\n",
       "          0.29520392,   0.24033008,   0.33576193,   0.34587221,\n",
       "          0.46854181,   0.44997201,   0.65377712,   0.62460961,\n",
       "          0.82110138,   0.70549273,   0.26673822,   0.24932523,\n",
       "          0.3538363 ,   0.34160495,   0.46411967,   0.44830399,\n",
       "          0.73004241,   0.6300282 ,   1.03001866,   0.93223257,\n",
       "          0.30559053,   0.25304918,   0.34550004,   0.35168757,\n",
       "          0.63698215,   0.50619502,   1.05637722,   1.19984031,\n",
       "          1.46808848,   1.17917781,   0.37453079,   0.24767613,\n",
       "          0.37119503,   0.35906954,   0.80455604,   0.69701829,\n",
       "          1.03497729,   0.91497073,   1.44468303,   1.77734146,\n",
       "          0.51009245,   0.27016587,   0.41542873,   0.42566013,\n",
       "          0.76876407,   0.69348383,   1.54277487,   1.23161306,\n",
       "          1.86204596,   0.93946123]),\n",
       " 'std_score_time': array([8.82761608e-02, 1.21884119e-02, 1.95040726e-02, 1.29754459e-02,\n",
       "        1.90165698e-02, 2.57214579e-02, 3.83285539e-02, 2.30503267e-02,\n",
       "        3.65721982e-02, 2.31529926e-02, 1.69592443e-02, 6.61218222e-03,\n",
       "        9.32462669e-03, 2.67385540e-02, 4.09329478e-02, 1.26817258e-02,\n",
       "        3.60964756e-02, 2.36032258e-02, 2.94592436e-02, 4.44626801e-02,\n",
       "        1.35263413e-02, 9.80453241e-03, 1.89959082e-02, 2.19645856e-02,\n",
       "        1.23805367e-02, 1.75105149e-02, 5.48544963e-02, 4.49528055e-02,\n",
       "        8.10276490e-03, 2.84270939e-02, 1.26251349e-02, 8.98965634e-03,\n",
       "        1.49511129e-02, 7.58997782e-03, 1.65634009e-02, 2.21032830e-02,\n",
       "        4.43841469e-02, 2.68291084e-02, 3.39636270e-02, 4.67652817e-02,\n",
       "        1.92421634e-02, 1.14895065e-02, 1.36311379e-02, 1.52313641e-02,\n",
       "        4.99555848e-02, 1.39147868e-02, 1.48726362e-02, 4.90670261e-02,\n",
       "        3.99399420e-02, 5.70115864e-02, 1.85008306e-02, 1.76771429e-02,\n",
       "        3.71372056e-02, 2.95305913e-02, 3.30255188e-02, 2.30619189e-02,\n",
       "        2.67750125e-02, 3.66848141e-02, 3.09251773e-02, 5.20758732e-02,\n",
       "        1.84145875e-02, 2.22809802e-02, 1.46925358e-02, 2.17206860e-02,\n",
       "        1.50488306e-02, 1.24186684e-02, 2.34539346e-02, 4.70668658e-02,\n",
       "        2.61046207e-02, 5.57584698e-02, 1.96642101e-02, 1.00930468e-02,\n",
       "        1.75344542e-02, 1.06714108e-02, 1.39381897e-02, 3.93754208e-02,\n",
       "        1.84572236e-02, 2.50724981e-02, 2.82163137e-02, 5.18473897e-02,\n",
       "        9.35390150e-02, 7.78126712e-03, 6.27431970e-03, 1.66074589e-02,\n",
       "        3.86718805e-02, 1.26513639e-02, 2.03795095e-02, 6.09184302e-03,\n",
       "        3.37249310e-02, 1.10968332e-01, 4.09230130e-02, 1.61120888e-02,\n",
       "        2.70356270e+02, 6.66300494e-02, 3.97551131e-02, 7.09169520e-02,\n",
       "        3.36790409e-02, 5.06128190e-02, 3.12470555e-02, 6.37763807e-02,\n",
       "        5.04881826e-02, 2.17278763e-02, 1.58869821e-02, 1.45552413e-02,\n",
       "        2.33840374e-02, 1.86330971e-02, 1.48741901e-02, 3.05278829e-02,\n",
       "        8.23552264e-02, 3.77998805e-02, 1.92199491e-02, 7.50668600e-03,\n",
       "        5.48428858e-02, 9.35704167e-03, 1.67934250e-02, 4.90379794e-02,\n",
       "        1.87640082e-02, 2.94744464e-02, 4.47862488e-02, 1.50416987e-01,\n",
       "        4.12379615e-02, 2.83373843e-02, 1.95618743e-02, 1.37563141e-02,\n",
       "        6.67193997e-02, 7.77300525e-02, 3.74668447e-01, 3.36449842e-01,\n",
       "        1.93229042e-01, 2.90216009e-01, 1.35626992e-01, 1.61551160e-02,\n",
       "        2.34374024e-02, 4.25084761e-02, 1.15928355e-01, 1.49172746e-01,\n",
       "        9.47495524e-02, 1.11778122e-01, 3.65910400e-01, 2.62178028e-01,\n",
       "        2.13673445e-01, 9.86232819e-03, 4.95022457e-02, 6.54946766e-02,\n",
       "        5.85690117e-02, 8.08841911e-02, 3.39403658e-01, 2.34288700e-01,\n",
       "        2.51902422e-01, 4.90909957e-01]),\n",
       " 'param_rf_clf__max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,\n",
       "                    11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "                    12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14,\n",
       "                    14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_rf_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2),\n",
       "                    (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1),\n",
       "                    (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3),\n",
       "                    (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1),\n",
       "                    (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5),\n",
       "                    (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5),\n",
       "                    (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2),\n",
       "                    (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1),\n",
       "                    (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 5), (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3),\n",
       "                    (1, 3), (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1),\n",
       "                    (1, 2), (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5),\n",
       "                    (1, 5), (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 1), (1, 1), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 4), (1, 4), (1, 5), (1, 5),\n",
       "                    (1, 1), (1, 1), (1, 2), (1, 2), (1, 3), (1, 3), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_rf_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 1,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 2,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 3,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 4,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 5,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 6,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 7,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 8,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 9,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 10,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 11,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 12,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 13,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 14,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 1),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 2),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 3),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 4),\n",
       "   'rf_tfidf__use_idf': False},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': True},\n",
       "  {'rf_clf__max_depth': 15,\n",
       "   'rf_tfidf__ngram_range': (1, 5),\n",
       "   'rf_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5605, 0.5605,\n",
       "        0.5615, 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.5605, 0.561 , 0.561 , 0.5615, 0.5615, 0.561 , 0.561 , 0.5605,\n",
       "        0.5605, 0.561 , 0.5605, 0.5605, 0.561 , 0.5615, 0.5615, 0.561 ,\n",
       "        0.561 , 0.5615, 0.5615, 0.5605, 0.5615, 0.5605, 0.562 , 0.5615,\n",
       "        0.562 , 0.561 , 0.5615, 0.5615, 0.56  , 0.5615, 0.5615, 0.561 ,\n",
       "        0.562 , 0.562 , 0.5615, 0.5615, 0.5615, 0.5615, 0.561 , 0.561 ,\n",
       "        0.5645, 0.563 , 0.561 , 0.5615, 0.561 , 0.5615, 0.5615, 0.561 ,\n",
       "        0.5575, 0.563 , 0.562 , 0.5625, 0.563 , 0.5625, 0.5615, 0.562 ,\n",
       "        0.562 , 0.5615, 0.5645, 0.563 , 0.561 , 0.563 , 0.5635, 0.5615,\n",
       "        0.562 , 0.5615, 0.561 , 0.562 , 0.565 , 0.566 , 0.5625, 0.565 ,\n",
       "        0.5645, 0.564 , 0.5635, 0.562 , 0.5615, 0.5615]),\n",
       " 'split1_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.5615, 0.561 , 0.561 , 0.561 , 0.5615, 0.5605,\n",
       "        0.561 , 0.561 , 0.5615, 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.5615, 0.561 , 0.5615, 0.561 , 0.5615, 0.561 , 0.561 ,\n",
       "        0.561 , 0.5615, 0.563 , 0.5615, 0.562 , 0.561 , 0.561 , 0.562 ,\n",
       "        0.561 , 0.5615, 0.561 , 0.5615, 0.562 , 0.5625, 0.565 , 0.561 ,\n",
       "        0.5615, 0.562 , 0.561 , 0.5615, 0.561 , 0.562 , 0.564 , 0.564 ,\n",
       "        0.5625, 0.5635, 0.5615, 0.5635, 0.5615, 0.562 , 0.562 , 0.5615,\n",
       "        0.564 , 0.564 , 0.564 , 0.5625, 0.5635, 0.564 , 0.564 , 0.5615,\n",
       "        0.561 , 0.5615, 0.5645, 0.566 , 0.5635, 0.5655, 0.566 , 0.564 ,\n",
       "        0.5645, 0.564 , 0.565 , 0.5625, 0.5655, 0.5685, 0.5685, 0.5655,\n",
       "        0.567 , 0.566 , 0.566 , 0.5645, 0.564 , 0.562 ]),\n",
       " 'split2_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.5605, 0.561 , 0.561 , 0.561 , 0.5615, 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.5605, 0.5605, 0.5615, 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.562 ,\n",
       "        0.5645, 0.561 , 0.5625, 0.5615, 0.5615, 0.561 , 0.5615, 0.561 ,\n",
       "        0.561 , 0.5605, 0.562 , 0.562 , 0.5605, 0.5615, 0.562 , 0.562 ,\n",
       "        0.5615, 0.5615, 0.563 , 0.565 , 0.558 , 0.561 , 0.563 , 0.5645,\n",
       "        0.562 , 0.5625, 0.562 , 0.5615, 0.566 , 0.5645, 0.566 , 0.562 ,\n",
       "        0.5595, 0.5615, 0.5615, 0.5615, 0.561 , 0.5625, 0.562 , 0.5665,\n",
       "        0.562 , 0.565 , 0.5645, 0.562 , 0.561 , 0.562 , 0.5635, 0.5615,\n",
       "        0.562 , 0.566 , 0.5635, 0.5635, 0.561 , 0.565 , 0.5625, 0.565 ,\n",
       "        0.5635, 0.561 , 0.565 , 0.5665, 0.564 , 0.568 , 0.5655, 0.5645,\n",
       "        0.562 , 0.5615, 0.5605, 0.56  , 0.5675, 0.567 , 0.565 , 0.5635,\n",
       "        0.5645, 0.567 , 0.5655, 0.559 , 0.562 , 0.56  ]),\n",
       " 'split3_test_score': array([0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5615, 0.5615,\n",
       "        0.561 , 0.562 , 0.561 , 0.561 , 0.562 , 0.561 , 0.561 , 0.561 ,\n",
       "        0.562 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.561 , 0.5615,\n",
       "        0.561 , 0.561 , 0.561 , 0.5625, 0.5615, 0.561 , 0.562 , 0.5615,\n",
       "        0.561 , 0.5625, 0.5615, 0.5615, 0.564 , 0.5635, 0.562 , 0.5625,\n",
       "        0.562 , 0.563 , 0.562 , 0.5615, 0.5615, 0.5615, 0.567 , 0.566 ,\n",
       "        0.5625, 0.5635, 0.5635, 0.564 , 0.5625, 0.562 , 0.5615, 0.5635,\n",
       "        0.566 , 0.5635, 0.5635, 0.5645, 0.5635, 0.5635, 0.564 , 0.564 ,\n",
       "        0.5615, 0.563 , 0.566 , 0.5685, 0.5675, 0.5645, 0.563 , 0.566 ,\n",
       "        0.5625, 0.5645, 0.5635, 0.564 , 0.5695, 0.5685, 0.567 , 0.564 ,\n",
       "        0.563 , 0.5635, 0.564 , 0.564 , 0.5625, 0.5625]),\n",
       " 'split4_test_score': array([0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.5615, 0.562 , 0.5615,\n",
       "        0.5615, 0.5615, 0.562 , 0.562 , 0.5615, 0.5615, 0.5615, 0.5615,\n",
       "        0.5615, 0.562 , 0.562 , 0.563 , 0.562 , 0.5615, 0.5625, 0.5615,\n",
       "        0.5615, 0.5615, 0.5635, 0.5625, 0.5635, 0.563 , 0.562 , 0.5625,\n",
       "        0.5615, 0.562 , 0.5615, 0.562 , 0.563 , 0.5625, 0.564 , 0.5625,\n",
       "        0.563 , 0.563 , 0.563 , 0.5625, 0.562 , 0.5615, 0.564 , 0.5655,\n",
       "        0.564 , 0.5645, 0.5635, 0.564 , 0.5635, 0.5625, 0.5635, 0.562 ,\n",
       "        0.565 , 0.566 , 0.5645, 0.5635, 0.564 , 0.5645, 0.563 , 0.564 ,\n",
       "        0.565 , 0.564 , 0.5655, 0.567 , 0.5665, 0.5635, 0.5675, 0.565 ,\n",
       "        0.5635, 0.5625, 0.565 , 0.564 , 0.567 , 0.566 , 0.5675, 0.5645,\n",
       "        0.567 , 0.564 , 0.565 , 0.5665, 0.563 , 0.5645]),\n",
       " 'mean_test_score': array([0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611, 0.5611,\n",
       "        0.5611, 0.5611, 0.561 , 0.5611, 0.5611, 0.5611, 0.5612, 0.5611,\n",
       "        0.5611, 0.5611, 0.5611, 0.5611, 0.561 , 0.561 , 0.5611, 0.561 ,\n",
       "        0.5612, 0.5611, 0.5612, 0.5611, 0.5611, 0.5611, 0.5615, 0.5613,\n",
       "        0.5617, 0.5613, 0.5616, 0.5614, 0.5615, 0.5611, 0.5612, 0.561 ,\n",
       "        0.5612, 0.5612, 0.5613, 0.5616, 0.5611, 0.5614, 0.5616, 0.5614,\n",
       "        0.5612, 0.5614, 0.5624, 0.5624, 0.5613, 0.5613, 0.562 , 0.5624,\n",
       "        0.5615, 0.5619, 0.5615, 0.5616, 0.563 , 0.5629, 0.5637, 0.5618,\n",
       "        0.5616, 0.5623, 0.5618, 0.5617, 0.5614, 0.5618, 0.5636, 0.5646,\n",
       "        0.5631, 0.5639, 0.5628, 0.563 , 0.5619, 0.562 , 0.5624, 0.5619,\n",
       "        0.5629, 0.5645, 0.5635, 0.5633, 0.563 , 0.5639, 0.563 , 0.5633,\n",
       "        0.5626, 0.5622, 0.5651, 0.5662, 0.5645, 0.5649, 0.5651, 0.5642,\n",
       "        0.5629, 0.5628, 0.563 , 0.5625, 0.5669, 0.5672, 0.5661, 0.5645,\n",
       "        0.5652, 0.5649, 0.5648, 0.5632, 0.5626, 0.5621]),\n",
       " 'std_test_score': array([0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.00031623, 0.0002    , 0.0002    , 0.0002    , 0.00024495,\n",
       "        0.0002    , 0.0002    , 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.00031623, 0.00031623, 0.00037417, 0.00031623, 0.00024495,\n",
       "        0.0002    , 0.00024495, 0.0002    , 0.0002    , 0.0002    ,\n",
       "        0.00031623, 0.0005099 , 0.00143527, 0.0004    , 0.0005831 ,\n",
       "        0.00037417, 0.00031623, 0.0002    , 0.00024495, 0.00031623,\n",
       "        0.0005099 , 0.0005099 , 0.0006    , 0.00086023, 0.0004899 ,\n",
       "        0.0002    , 0.0005831 , 0.00037417, 0.00024495, 0.0002    ,\n",
       "        0.00096954, 0.00149666, 0.00180555, 0.00087178, 0.00063246,\n",
       "        0.00111355, 0.00044721, 0.0005831 , 0.00031623, 0.0002    ,\n",
       "        0.002     , 0.0010198 , 0.00172047, 0.00067823, 0.00115758,\n",
       "        0.0006    , 0.00067823, 0.0004    , 0.00037417, 0.0004    ,\n",
       "        0.00205913, 0.00198494, 0.00096954, 0.00073485, 0.00132665,\n",
       "        0.00104881, 0.00096954, 0.00031623, 0.00091652, 0.00086023,\n",
       "        0.00300666, 0.00126491, 0.00083666, 0.00074833, 0.00104881,\n",
       "        0.00086023, 0.00094868, 0.00132665, 0.00146287, 0.0011225 ,\n",
       "        0.0005831 , 0.00180555, 0.00230217, 0.001772  , 0.00165529,\n",
       "        0.00150333, 0.00096954, 0.001249  , 0.00192354, 0.00148324,\n",
       "        0.00159374, 0.0011225 , 0.00213073, 0.00070711, 0.00156844,\n",
       "        0.00135647, 0.00092736, 0.00254165, 0.00086023, 0.00146287]),\n",
       " 'rank_test_score': array([ 81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
       "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
       "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81,\n",
       "         81,  81,  81,  81,  81,  81,  81,  81,  81,  81,  81, 146,  81,\n",
       "         81,  81,  75,  81,  81,  81,  81,  81, 146, 146,  81, 146,  75,\n",
       "         81,  75,  81,  81,  81,  62,  70,  53,  70,  56,  64,  60,  81,\n",
       "         75, 146,  74,  75,  69,  56,  81,  67,  55,  64,  75,  67,  38,\n",
       "         38,  72,  72,  45,  38,  60,  47,  62,  56,  25,  30,  18,  50,\n",
       "         56,  42,  50,  54,  64,  50,  19,  11,  24,  16,  33,  26,  47,\n",
       "         45,  38,  47,  32,  14,  20,  21,  26,  16,  26,  21,  35,  43,\n",
       "          6,   3,  12,   8,   6,  15,  30,  33,  26,  37,   2,   1,   4,\n",
       "         12,   5,   8,  10,  23,  35,  44])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid-search parameter optimization\n",
    "#random forest classifier parameters\n",
    "parameters = {'rf_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'rf_tfidf__use_idf': (True, False),\n",
    "               'rf_clf__max_depth': (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(random_forest_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc94951-9c9e-47d9-b512-eba49b7c218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression parameters\n",
    "parameters = {'LogR_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'LogR_tfidf__use_idf': (True, False),\n",
    "               'LogR_tfidf__smooth_idf': (True, False)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(logR_pipeline_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ed22d-d2a6-44a6-a473-2719ba5d79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by running above commands we can find the model with best performing parameters\n",
    "\n",
    "\n",
    "#running both random forest and logistic regression models again with best parameter found with GridSearch method\n",
    "random_forest_final = Pipeline([\n",
    "        ('rf_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,3),use_idf=True,smooth_idf=True)),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3,max_depth=10))\n",
    "        ])\n",
    "    \n",
    "random_forest_final.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_rf_final = random_forest_final.predict(test_news['Statement'])\n",
    "np.mean(predicted_rf_final == test_news['Label'])\n",
    "print(classification_report(test_news['Label'], predicted_rf_final))\n",
    "\n",
    "logR_pipeline_final = Pipeline([\n",
    "        #('LogRCV',countV_ngram),\n",
    "        ('LogR_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,5),use_idf=True,smooth_idf=False)),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_final.fit(train_news['Statement'],train_news['Label'])\n",
    "predicted_LogR_final = logR_pipeline_final.predict(test_news['Statement'])\n",
    "np.mean(predicted_LogR_final == test_news['Label'])\n",
    "#accuracy = 0.62\n",
    "print(classification_report(test_news['Label'], predicted_LogR_final))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8964a98-9839-49db-ac42-0007d9e42ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "by running both random forest and logistic regression with GridSearch's best parameter estimation, we found that for random \n",
    "forest model with n-gram has better accuracty than with the parameter estimated. The logistic regression model with best parameter \n",
    "has almost similar performance as n-gram model so logistic regression will be out choice of model for prediction.\n",
    "\"\"\"\n",
    "\n",
    "#saving best model to the disk\n",
    "model_file = 'final_model.sav'\n",
    "pickle.dump(logR_pipeline_ngram,open(model_file,'wb'))\n",
    "\n",
    "\n",
    "#Plotting learing curve\n",
    "def plot_learing_curve(pipeline,title):\n",
    "    size = 10000\n",
    "    cv = KFold(size, shuffle=True)\n",
    "    \n",
    "    X = DataPrep.train_news[\"Statement\"]\n",
    "    y = DataPrep.train_news[\"Label\"]\n",
    "    \n",
    "    pl = pipeline\n",
    "    pl.fit(X,y)\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(pl, X, y, n_jobs=-1, cv=cv, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "       \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "     \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c955859d-7420-4f66-8e69-66285e23a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#below command will plot learing curves for each of the classifiers\n",
    "plot_learing_curve(logR_pipeline_ngram,\"Naive-bayes Classifier\")\n",
    "plot_learing_curve(nb_pipeline_ngram,\"LogisticRegression Classifier\")\n",
    "plot_learing_curve(svm_pipeline_ngram,\"SVM Classifier\")\n",
    "plot_learing_curve(sgd_pipeline_ngram,\"SGD Classifier\")\n",
    "plot_learing_curve(random_forest_ngram,\"RandomForest Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993cf784-a40a-42d3-8a19-701597211c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "by plotting the learning cureve for logistic regression, it can be seen that cross-validation score is stagnating throughout and it \n",
    "is unable to learn from data. Also we see that there are high errors that indicates model is simple and we may want to increase the\n",
    "model complexity.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#plotting Precision-Recall curve\n",
    "def plot_PR_curve(classifier):\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(DataPrep.test_news['Label'], classifier)\n",
    "    average_precision = average_precision_score(DataPrep.test_news['Label'], classifier)\n",
    "    \n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Random Forest Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "              average_precision))\n",
    "    \n",
    "plot_PR_curve(predicted_LogR_ngram)\n",
    "plot_PR_curve(predicted_rf_ngram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf66ce3-379c-48a9-b932-22e1b76c4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now let's extract the most informative feature from ifidf vectorizer for all fo the classifiers and see of there are any common\n",
    "words that we can identify i.e. are these most informative feature acorss the classifiers are same? we will create a function that \n",
    "will extract top 50 features.\n",
    "\"\"\"\n",
    "\n",
    "def show_most_informative_features(model, vect, clf, text=None, n=50):\n",
    "    # Extract the vectorizer and the classifier from the pipeline\n",
    "    vectorizer = model.named_steps[vect]\n",
    "    classifier = model.named_steps[clf]\n",
    "\n",
    "     # Check to make sure that we can perform this computation\n",
    "    if not hasattr(classifier, 'coef_'):\n",
    "        raise TypeError(\n",
    "            \"Cannot compute most informative features on {}.\".format(\n",
    "                classifier.__class__.__name__\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    if text is not None:\n",
    "        # Compute the coefficients for the text\n",
    "        tvec = model.transform([text]).toarray()\n",
    "    else:\n",
    "        # Otherwise simply use the coefficients\n",
    "        tvec = classifier.coef_\n",
    "\n",
    "    # Zip the feature names with the coefs and sort\n",
    "    coefs = sorted(\n",
    "        zip(tvec[0], vectorizer.get_feature_names()),\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Get the top n and bottom n coef, name pairs\n",
    "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
    "\n",
    "    # Create the output string to return\n",
    "    output = []\n",
    "\n",
    "    # If text, add the predicted value to the output.\n",
    "    if text is not None:\n",
    "        output.append(\"\\\"{}\\\"\".format(text))\n",
    "        output.append(\n",
    "            \"Classified as: {}\".format(model.predict([text]))\n",
    "        )\n",
    "        output.append(\"\")\n",
    "\n",
    "    # Create two columns with most negative and most positive features.\n",
    "    for (cp, fnp), (cn, fnn) in topn:\n",
    "        output.append(\n",
    "            \"{:0.4f}{: >15}    {:0.4f}{: >15}\".format(\n",
    "                cp, fnp, cn, fnn\n",
    "            )\n",
    "        )\n",
    "    #return \"\\n\".join(output)\n",
    "    print(output)\n",
    "\n",
    "show_most_informative_features(logR_pipeline_ngram,vect='LogR_tfidf',clf='LogR_clf')\n",
    "show_most_informative_features(nb_pipeline_ngram,vect='nb_tfidf',clf='nb_clf')\n",
    "show_most_informative_features(svm_pipeline_ngram,vect='svm_tfidf',clf='svm_clf')\n",
    "show_most_informative_features(sgd_pipeline_ngram,vect='sgd_tfidf',clf='sgd_clf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81960436-79f3-461f-b33d-e14d38005602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3a79d-60cb-4255-bbd0-5181efd5755d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
